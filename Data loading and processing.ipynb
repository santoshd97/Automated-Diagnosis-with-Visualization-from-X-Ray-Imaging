{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to load all images along with labels since labels are given in csv file along with image path\n",
    "## Link to CheXpert dataset: https://stanfordmlgroup.github.io/competitions/chexpert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimension imdim x imdim\n",
    "imdim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 224, 224, 1)\n",
      "[[0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0]\n",
      " [0.0 1.0 0.0 1.0 0.0 1.0 1.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0]\n",
      " [0.0 1.0 1.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0]\n",
      " [0.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0]\n",
      " [0.0 0.0 0.0 1.0 0.0 1.0 1.0 0.0 1.0 1.0 1.0 0.0 0.0 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Loading Validation Images and Labels\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "vlabel = pd.read_csv('/Users/santoshdaptardar/Documents/CheXpert-v1.0-small/valid.csv')\n",
    "vlabel = vlabel[vlabel['Frontal/Lateral'].isin(['Frontal'])]\n",
    "#print(vlabel)\n",
    "docu_path = '/Users/santoshdaptardar/Documents'\n",
    "vdata = []; vlabels = []\n",
    "for (p,i) in zip(vlabel.iloc[:,0], range(vlabel['Path'].count())):\n",
    "    p1 = p.split('/')\n",
    "    image_name = p1.pop()\n",
    "    p2 = '/'.join(p1)\n",
    "    os.chdir(docu_path + '/' + p2)\n",
    "    vv = np.array(Image.open(image_name).resize((imdim,imdim))).reshape(imdim,imdim)/255.0\n",
    "    vdata.extend([vv[:,:,np.newaxis]])\n",
    "    vlabels.extend([vlabel.iloc[i, 5:19].to_numpy()])\n",
    "vdata = np.asarray(vdata)\n",
    "vlabels = np.asarray(vlabels)\n",
    "print(vdata.shape)\n",
    "print(vlabels[100:105,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2973537047f4c5d862ffc80329fbcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]]\n",
      "(50000, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading Training images and labels\n",
    "\n",
    "import os, pandas as pd, numpy as np, matplotlib.pyplot as plt, pickle\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "vlabel = pd.read_csv('/Users/santoshdaptardar/Documents/CheXpert-v1.0-small/train.csv')\n",
    "vlabel = vlabel[vlabel['Frontal/Lateral'].isin(['Frontal'])]\n",
    "vlabel = vlabel.fillna(0)\n",
    "#print(vlabel)\n",
    "docu_path = '/Users/santoshdaptardar/Documents'\n",
    "data = []\n",
    "labels = []\n",
    "total =  50000 #vlabel['Path'].count() # no. of images to load\n",
    "for (p,i) in zip(vlabel.iloc[:,0], tqdm(range(total))):\n",
    "    #if (i+1)%2000 == 0: print(i+1,'/',total,'completed!')\n",
    "    p1 = p.split('/')\n",
    "    image_name = p1.pop()\n",
    "    p2 = '/'.join(p1)\n",
    "    os.chdir(docu_path + '/' + p2)\n",
    "    dd = np.array(Image.open(image_name).resize((imdim,imdim))).reshape(imdim,imdim)/255.0\n",
    "    data.extend([dd[:,:, np.newaxis]])\n",
    "    l = vlabel.iloc[i, 5:19].astype(float).to_numpy()\n",
    "    labels.extend([np.where(l==-1, 0, l)]) # replace -1 with 0\n",
    "data = np.asarray(data)\n",
    "labels = np.asarray(labels)\n",
    "print(labels[:10,])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle train and test data and labels into a file for easy loading\n",
    "import bz2\n",
    "\n",
    "os.chdir('/Users/santoshdaptardar/Documents/Deep Learning/Project')\n",
    "\n",
    "with bz2.BZ2File('train_data_1_128.pbz2','w') as f:\n",
    "    pickle.dump(data[:30000,:],f)\n",
    "    \n",
    "with bz2.BZ2File('train_data_2_128.pbz2','w') as f:\n",
    "    pickle.dump(data[30000:60000,:],f)\n",
    "    \n",
    "with bz2.BZ2File('train_data_3_128.pbz2','w') as f:\n",
    "    pickle.dump(data[60000:90000,:],f)\n",
    "\n",
    "with bz2.BZ2File('train_data_4_128.pbz2','w') as f:\n",
    "    pickle.dump(data[90000:120000,:],f)\n",
    "\n",
    "with bz2.BZ2File('train_data_5_128.pbz2','w') as f:\n",
    "    pickle.dump(data[120000:150000,:],f)\n",
    "\n",
    "with bz2.BZ2File('train_data_6_128.pbz2','w') as f:\n",
    "    pickle.dump(data[150000:180000,:],f)\n",
    "\n",
    "with bz2.BZ2File('train_data_7_128.pbz2','w') as f:\n",
    "    pickle.dump(data[180000:,:],f)\n",
    "\n",
    "with bz2.BZ2File('train_label_128.pbz2','w') as f:\n",
    "    pickle.dump(labels, f)\n",
    "\n",
    "with bz2.BZ2File('test_data_128.pbz2','w') as f:\n",
    "    pickle.dump(vdata, f)\n",
    "\n",
    "with bz2.BZ2File('test_label_128.pbz2','w') as f:\n",
    "    pickle.dump(vlabels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
